#!/usr/bin/env python

import datetime
import os
import shutil
import sys
import contextlib
import time
import threading
import json

try:
    import thread
except ImportError:
    import _thread as thread

from multiprocessing import Pool
from glob import glob
from itertools import product
from collections import defaultdict
from statistics import mean, stdev

POOL_SIZE = 3
#POOL_SIZE = 1

TIMEOUT = 300

POS_EXAMPLES = 2
NEG_EXAMPLES = 0 # NB: ignored for now
CLAUSES = 1
TRIALS = 2

MIN_SIZE = 1
MAX_SIZE = 5

goldilocks = None
sys.path.append("../../systems/goldilocks/")
import chimera.main as goldilocks
from chimera.util import working_directory

def main(args):
    print('blah')
    constraintness, trial, size = args
    flag = "constrainted" if constraintness else "unconstrainted"
    task_name = f"{flag}-size_{size}-trial_{trial}"
    with working_directory("./" + task_name), \
         open("parameters.pl", "w") as params, \
         open("examples.pl", "w") as examples, \
         open("result.txt", "w") as results:
        max_vars = size
        params.write(\
f"max_vars({max_vars+1}).\nmax_body({size}).\nmax_clauses({CLAUSES}).\n" + \
f"max_pos_x({size}).\nmax_pos_y(0).\n"
)
        params.flush()

        examples.write(\
f"pos(f(w(0,0,1,1,0),w({size},0,1,1,0))).\n"
)
        examples.flush()

        for file_ in glob("../../*.asp.pl") + glob("../../*.prolog.pl"):
            shutil.copyfile(file_, os.path.basename(file_))

        task_path = os.path.dirname(os.path.realpath(__file__)) + f"/{DATETIME}/{task_name}"

        before = time.time()

        timer = threading.Timer(TIMEOUT, lambda: thread.interrupt_main())
        timer.start()
        try:
            program = goldilocks.main(os.getcwd(), {'constrain_specializations': constraintness})
        except KeyboardInterrupt:
            program = False  # NB: signifies synthesizer did not return
        finally:
            timer.cancel()

        after = time.time()

        result = {'constraintness': constraintness,
                  'size': size,
                  'trial': trial,
                  'time': after - before,
                  'program': program}

        print(json.dumps(result), file=results)
        print(json.dumps(result))

        return result

if __name__ == "__main__":
    DATETIME = str(datetime.datetime.now())
    with working_directory("./" + DATETIME):
        with Pool(POOL_SIZE) as pool:
            constraintness = [True,False]
            trials = range(1, TRIALS+1)
            sizes = range(MIN_SIZE, MAX_SIZE + 1)
            process_args = product(constraintness, trials, sizes)
            #process_args = [(True,1,10)]
            results = pool.map(main, process_args)
            collected_results = defaultdict(lambda: defaultdict(list))
            for res in results:
                collected_results[res['constraintness']][res['size']] += [res['time']]

            with open("results.txt", 'w') as results:
                mean_times = defaultdict(lambda: defaultdict(dict))
                for i in sizes:
                    times = collected_results[True][i]
                    mean_times['constrainted'][i] = {'mean': mean(times), 'stdev': stdev(times)}
                    times = collected_results[False][i]
                    mean_times['unconstrainted'][i] = {'mean': mean(times), 'stdev': stdev(times)}
                results.write(json.dumps(mean_times, indent=2))


            
