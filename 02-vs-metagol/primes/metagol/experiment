#!/usr/bin/env python

import datetime
import os
import shutil
import sys
import contextlib
import time
import threading
import subprocess
import json

try:
    import thread
except ImportError:
    import _thread as thread

from multiprocessing import Pool
from glob import glob
from itertools import product
from functools import reduce
from collections import defaultdict
from statistics import mean, stdev


NR_BOTTOMS = 10


POOL_SIZE = 3
#POOL_SIZE = 1

TIMEOUT = 120

TRIALS = 2

MIN_SIZE = 1
MAX_SIZE = 10

goldilocks = None
sys.path.append("../../../systems/goldilocks/")
import chimera.main as goldilocks
from chimera.util import working_directory

def main(args):
    trial, size = args
    task_name = f"size_{size}-trial_{trial}"
    with working_directory("./" + task_name), \
         open("bk.prolog.pl", "w") as prolog_bk, \
         open("parameters.pl", "w") as params, \
         open("train.pl", "w") as examples, \
         open("result.txt", "w") as results:
        params.write(f"""\
metagol:functional.
metagol:max_clauses({size-1}).
SIZE({size}).
NR_BOTTOMS({NR_BOTTOMS}).
"""
)
        params.flush()

        primes10 = [2,3,5,7,11,13,17,19,23,29]
        primes = primes10[:size]
        bk_preds = '\n'.join(f"body_pred(div{p}/1)." for p in primes)
        bk_bottoms = '\n'.join(f"body_pred(bottom{n}/1)." for n in range(NR_BOTTOMS))
        prolog_bk.write("metarule(unary_chain, [P,Q,R], [P,A], [[Q,A],[R,A]]).\n\n" + bk_preds + "\n\n" + bk_bottoms)
        prolog_bk.flush()

        product = reduce(lambda x, y: x*y, primes)
        pos_exs, neg_exs = [product], [product//p for p in primes]

        examples.write(f"""\
:- use_module('../../metagol').
:- include('../../unary.pl').
:- include('bk.prolog.pl').

goal :- 
    Pos = [{','.join('f(' + str(p) + ')' for p in pos_exs)}],
    Neg = [{','.join('f(' + str(p) + ')' for p in neg_exs)}],
    learn(Pos,Neg).
"""
)
        examples.flush()

        before = time.time()

#        timer = threading.Timer(TIMEOUT, lambda: print('a') or thread.interrupt_main())
#        timer.start()
        try:
            cp = subprocess.run(['swipl', '-l', 'train.pl', '-g', 'goal', '-g', 'halt'],
                                stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                timeout=TIMEOUT)
            print(cp.stdout)
            print(cp.stderr)
            print(cp.returncode)
            program = cp.stdout.decode('utf-8')
        except subprocess.TimeoutExpired:
            program = False  # NB: signifies synthesizer did not return
#        finally:
#            timer.cancel()

        after = time.time()

        result = {'size': size,
                  'trial': trial,
                  'time': after - before,
                  'program': program}

        print(json.dumps(result, indent=2), file=results)
        print(json.dumps(result, indent=2))

        return result

if __name__ == "__main__":
    DATETIME = str(datetime.datetime.now())
    with working_directory("./" + DATETIME):
        with Pool(POOL_SIZE) as pool:
            trials = range(1, TRIALS+1)
            sizes = range(MIN_SIZE, MAX_SIZE + 1)
            process_args = product(trials, sizes)
            #process_args = [(True,1,10)]
            results = pool.map(main, process_args)
            collected_results = defaultdict(list)
            for res in results:
                collected_results[res['size']] += [res['time']]

            with open("results.txt", 'w') as results,\
                 open("results.table", 'w') as table:
                table.write("size time error\n")
                mean_times = defaultdict(dict)
                for i in sizes:
                    times = collected_results[i]
                    mean_times[i] = {'mean': mean(times), 'stdev': stdev(times)}
                    table.write(f"{i} {mean(times)} {stdev(times)}\n")
                results.write(json.dumps(mean_times, indent=2))
